{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class input_file:\n",
    "    def __init__(self, file_path):\n",
    "        self.__path = str(file_path)\n",
    "        self.__raw_data = '' \n",
    "\n",
    "    def read_from_file(self):\n",
    "        file = open(self.__path, 'r')\n",
    "        self.__raw_data = file.readlines()\n",
    "        file.close()\n",
    "\n",
    "        for i in range(len(self.__raw_data)):\n",
    "            self.__raw_data[i] = self.__raw_data[i].rstrip('\\n')\n",
    "\n",
    "    def get_raw_data(self):\n",
    "        return self.__raw_data\n",
    "\n",
    "    def sort_iris_data(self):\n",
    "        temp = []\n",
    "\n",
    "        for data in self.__raw_data:\n",
    "            data = data.rstrip(', ')\n",
    "            data = data.split(',')\n",
    "\n",
    "            for i in range(len(data)):\n",
    "                try:\n",
    "                    data[i] = float(data[i])\n",
    "                except:\n",
    "                    print(f'raw data cant cast to float : {data[i]}')\n",
    "                    return None\n",
    "\n",
    "            temp.append(data)\n",
    "\n",
    "        return temp\n",
    "\n",
    "    def sort_wave_dataset(self):\n",
    "        x_data = []\n",
    "        y_data = []\n",
    "        \n",
    "        for i in range(len(self.__raw_data)):\n",
    "            self.__raw_data[i] = self.__raw_data[i].strip()\n",
    "            self.__raw_data[i] = self.__raw_data[i].lstrip('[')\n",
    "            self.__raw_data[i] = self.__raw_data[i].rstrip(']')\n",
    "            self.__raw_data[i] = self.__raw_data[i].strip()\n",
    "\n",
    "        x_head = self.__raw_data.index('X inputs:')\n",
    "        y_head = self.__raw_data.index('y target:')\n",
    "\n",
    "        for data in self.__raw_data[x_head+1:y_head]:\n",
    "            x_data.append(float(data))\n",
    "        \n",
    "        for data in self.__raw_data[y_head+1:]:\n",
    "            data = data.split()\n",
    "            for number in data:\n",
    "                y_data.append(float(number))\n",
    "\n",
    "        return [x_data, y_data]\n",
    "            \n",
    "    def sort_boston_dataset(self):\n",
    "        x_data = []\n",
    "        y_data = []\n",
    "\n",
    "        for data in self.__raw_data:\n",
    "            data = data.strip(',')\n",
    "            data = data.split(',')\n",
    "            temp = []\n",
    "\n",
    "            for i in range(len(data)):\n",
    "                if i != (len(data) - 1):\n",
    "                    temp.append(float(data[i]))\n",
    "                else:\n",
    "                    y_data.append(float(data[i]))\n",
    "\n",
    "            x_data.append(temp)        \n",
    "\n",
    "        return [x_data, y_data]\n",
    "    \n",
    "    def sort_forge_dataset(self):\n",
    "        x_data = []\n",
    "        y_data = []\n",
    "\n",
    "        for i in range(len(self.__raw_data)):\n",
    "            self.__raw_data[i] = self.__raw_data[i].strip()\n",
    "            self.__raw_data[i] = self.__raw_data[i].lstrip('[')\n",
    "            self.__raw_data[i] = self.__raw_data[i].rstrip(']')\n",
    "            self.__raw_data[i] = self.__raw_data[i].strip()\n",
    "\n",
    "        x_head = self.__raw_data.index('X inputs:')\n",
    "        y_head = self.__raw_data.index('y target:')\n",
    "\n",
    "        for line in self.__raw_data[x_head+1: y_head]:\n",
    "            raw = line.split()\n",
    "            temp = []\n",
    "\n",
    "            for data in raw:\n",
    "                temp.append(float(data))\n",
    "\n",
    "            x_data.append(temp)\n",
    "\n",
    "        for line in self.__raw_data[y_head+1:]:\n",
    "            raw = line.split()\n",
    "            \n",
    "            for data in raw:\n",
    "                y_data.append(float(data))\n",
    "        \n",
    "\n",
    "        return [x_data, y_data]\n",
    "\n",
    "    def sort_cancer_dataset(self):\n",
    "        x_data = []\n",
    "        y_data = []\n",
    "\n",
    "        for data in self.__raw_data[1:]:\n",
    "            data = data.split(',')\n",
    "\n",
    "            for i in range(len(data)):\n",
    "                data[i] = float(data[i])\n",
    "\n",
    "            temp = data[0:30]\n",
    "\n",
    "            x_data.append(temp)\n",
    "            y_data.append(data[30])\n",
    "\n",
    "        return [x_data, y_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logistic_reg:\n",
    "    def __init__(self, penalty_val, max_iter_val, C_val=1, fit_intercept_val=True, random_state_val=None):\n",
    "        self.__model = LogisticRegression(C=C_val, penalty=penalty_val, solver='liblinear', max_iter=max_iter_val, fit_intercept=fit_intercept_val, random_state=random_state_val)\n",
    "        self.__max_iter = max_iter_val\n",
    "        self.__solver = 'liblinear'\n",
    "        self.__C = C_val\n",
    "        self.__penalty=penalty_val\n",
    "        self.__cross_valid_train_score = None\n",
    "        self.__cross_valid_valid_score = None\n",
    "\n",
    "    def train(self, x_data, y_data):\n",
    "        self.__model.fit(x_data, y_data)\n",
    "\n",
    "    def predict(self, x_data):\n",
    "        return self.__model.predict(x_data)\n",
    "\n",
    "    def score(self, x_data, y_data):\n",
    "        return self.__model.score(x_data, y_data)\n",
    "\n",
    "    def cross_valid(self, x_train, y_train):\n",
    "\n",
    "        split_len = int(len(x_train)/5)\n",
    "\n",
    "        x_split = []\n",
    "        y_split = []\n",
    "\n",
    "        for i in range(4):\n",
    "            x_split.append(x_train[i*split_len:(i+1)*split_len, :])\n",
    "            y_split.append(y_train[i*split_len:(i+1)*split_len])\n",
    "\n",
    "        x_split.append(x_train[4*split_len:, :])\n",
    "        y_split.append(y_train[4*split_len:])\n",
    "\n",
    "        valid_score = float(0)\n",
    "        train_score = float(0)\n",
    "\n",
    "        for i in range(5):\n",
    "            \n",
    "            is_array_exsist = False\n",
    "\n",
    "            for j in range(5):\n",
    "                if(not is_array_exsist):\n",
    "                    is_array_exsist = True\n",
    "                    x_valid_train = np.array(x_split[j])\n",
    "                    y_valid_train = np.array(y_split[j])\n",
    "                    continue\n",
    "\n",
    "                if(j == i):\n",
    "                    pass\n",
    "                else:\n",
    "                    x_valid_train = np.vstack((x_valid_train, x_split[j]))\n",
    "                    y_valid_train = np.hstack((y_valid_train, y_split[j]))\n",
    "\n",
    "            self.train(x_valid_train, y_valid_train)\n",
    "            valid_score = valid_score  + self.__model.score(x_split[i], y_split[i])\n",
    "            train_score = train_score + self.__model.score(x_valid_train, y_valid_train)\n",
    "\n",
    "            # print(f'Ridge (alpha {self.ridge_alpha}) Boston, fold {i}, train/test score: ', end='')\n",
    "            # print(f'{self.__model.score(x_valid_train, y_valid_train):.2f}/{self.__model.score(x_split[i], y_split[i]):.2f}')\n",
    "\n",
    "        self.__model.fit(x_train, y_train)\n",
    "        self.__cross_valid_train_score = float(train_score/5)\n",
    "        self.__cross_valid_valid_score = float(valid_score/5)\n",
    "\n",
    "        print(f'logistic regression (C: {self.__C} max_iter: {self.__max_iter} penalty: {self.__penalty}) 5-fold cross validation train/test: {self.__cross_valid_train_score:.3f}/{self.__cross_valid_valid_score:.3f}')\n",
    "\n",
    "        return [self.__cross_valid_train_score, self.__cross_valid_valid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class random_forest:\n",
    "    def __init__(self, estimators_val=100, max_feature_val='auto', max_depth_val=None):\n",
    "        self.__model = RandomForestClassifier(n_estimators=estimators_val, max_features=max_feature_val, max_depth=max_depth_val)\n",
    "        self.__estimator = estimators_val\n",
    "        self.__max_feature = max_feature_val\n",
    "        self.__max_depth = max_depth_val\n",
    "        self.__cross_valid_train_score = None\n",
    "        self.__cross_valid_valid_score = None\n",
    "\n",
    "    def train(self, x_data, y_data):\n",
    "        self.__model.fit(x_data, y_data)\n",
    "\n",
    "    def predict(self, x_data):\n",
    "        return self.__model.predict(x_data)\n",
    "\n",
    "    def score(self, x_data, y_data):\n",
    "        return self.__model.score(x_data, y_data)\n",
    "\n",
    "    def cross_valid(self, x_train, y_train):\n",
    "\n",
    "        split_len = int(len(x_train)/5)\n",
    "\n",
    "        x_split = []\n",
    "        y_split = []\n",
    "\n",
    "        for i in range(4):\n",
    "            x_split.append(x_train[i*split_len:(i+1)*split_len, :])\n",
    "            y_split.append(y_train[i*split_len:(i+1)*split_len])\n",
    "\n",
    "        x_split.append(x_train[4*split_len:, :])\n",
    "        y_split.append(y_train[4*split_len:])\n",
    "\n",
    "        valid_score = float(0)\n",
    "        train_score = float(0)\n",
    "\n",
    "        for i in range(5):\n",
    "            \n",
    "            is_array_exsist = False\n",
    "\n",
    "            for j in range(5):\n",
    "                if(not is_array_exsist):\n",
    "                    is_array_exsist = True\n",
    "                    x_valid_train = np.array(x_split[j])\n",
    "                    y_valid_train = np.array(y_split[j])\n",
    "                    continue\n",
    "\n",
    "                if(j == i):\n",
    "                    pass\n",
    "                else:\n",
    "                    x_valid_train = np.vstack((x_valid_train, x_split[j]))\n",
    "                    y_valid_train = np.hstack((y_valid_train, y_split[j]))\n",
    "\n",
    "            self.train(x_valid_train, y_valid_train)\n",
    "            valid_score = valid_score  + self.__model.score(x_split[i], y_split[i])\n",
    "            train_score = train_score + self.__model.score(x_valid_train, y_valid_train)\n",
    "\n",
    "            # print(f'Ridge (alpha {self.ridge_alpha}) Boston, fold {i}, train/test score: ', end='')\n",
    "            # print(f'{self.__model.score(x_valid_train, y_valid_train):.2f}/{self.__model.score(x_split[i], y_split[i]):.2f}')\n",
    "\n",
    "        self.__model.fit(x_train, y_train)\n",
    "        self.__cross_valid_train_score = float(train_score/5)\n",
    "        self.__cross_valid_valid_score = float(valid_score/5)\n",
    "\n",
    "        print(f'random forests (estimators: {self.__estimator} max_depth: {self.__max_depth} max_feature: {self.__max_feature}) 5-fold cross validation train/test: {self.__cross_valid_train_score:.3f}/{self.__cross_valid_valid_score:.3f}')\n",
    "\n",
    "        return [self.__cross_valid_train_score, self.__cross_valid_valid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gradient_boost_reg:\n",
    "    def __init__(self, estimators_val=100, learning_rate_val=0.1):\n",
    "        self.__model = GradientBoostingClassifier(n_estimators=estimators_val, learning_rate=learning_rate_val)\n",
    "        self.__estimator = estimators_val\n",
    "        self.__learning_rate = learning_rate_val\n",
    "        self.__cross_valid_train_score = None\n",
    "        self.__cross_valid_valid_score = None\n",
    "\n",
    "    def train(self, x_data, y_data):\n",
    "        self.__model.fit(x_data, y_data)\n",
    "\n",
    "    def predict(self, x_data):\n",
    "        return self.__model.predict(x_data)\n",
    "\n",
    "    def score(self, x_data, y_data):\n",
    "        return self.__model.score(x_data, y_data)\n",
    "\n",
    "    def cross_valid(self, x_train, y_train):\n",
    "\n",
    "        split_len = int(len(x_train)/5)\n",
    "\n",
    "        x_split = []\n",
    "        y_split = []\n",
    "\n",
    "        for i in range(4):\n",
    "            x_split.append(x_train[i*split_len:(i+1)*split_len, :])\n",
    "            y_split.append(y_train[i*split_len:(i+1)*split_len])\n",
    "\n",
    "        x_split.append(x_train[4*split_len:, :])\n",
    "        y_split.append(y_train[4*split_len:])\n",
    "\n",
    "        valid_score = float(0)\n",
    "        train_score = float(0)\n",
    "\n",
    "        for i in range(5):\n",
    "            \n",
    "            is_array_exsist = False\n",
    "\n",
    "            for j in range(5):\n",
    "                if(not is_array_exsist):\n",
    "                    is_array_exsist = True\n",
    "                    x_valid_train = np.array(x_split[j])\n",
    "                    y_valid_train = np.array(y_split[j])\n",
    "                    continue\n",
    "\n",
    "                if(j == i):\n",
    "                    pass\n",
    "                else:\n",
    "                    x_valid_train = np.vstack((x_valid_train, x_split[j]))\n",
    "                    y_valid_train = np.hstack((y_valid_train, y_split[j]))\n",
    "\n",
    "            self.train(x_valid_train, y_valid_train)\n",
    "            valid_score = valid_score  + self.__model.score(x_split[i], y_split[i])\n",
    "            train_score = train_score + self.__model.score(x_valid_train, y_valid_train)\n",
    "\n",
    "            # print(f'Ridge (alpha {self.ridge_alpha}) Boston, fold {i}, train/test score: ', end='')\n",
    "            # print(f'{self.__model.score(x_valid_train, y_valid_train):.2f}/{self.__model.score(x_split[i], y_split[i]):.2f}')\n",
    "\n",
    "        self.__model.fit(x_train, y_train)\n",
    "        self.__cross_valid_train_score = float(train_score/5)\n",
    "        self.__cross_valid_valid_score = float(valid_score/5)\n",
    "\n",
    "        print(f'gradient_boost_regression (estimator: {self.__estimator} learning_rate: {self.__learning_rate}) 5-fold cross validation train/test: {self.__cross_valid_train_score:.3f}/{self.__cross_valid_valid_score:.3f}')\n",
    "\n",
    "        return [self.__cross_valid_train_score, self.__cross_valid_valid_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression (C: 10 max_iter: 1000 penalty: l2) 5-fold cross validation train/test: 0.965/0.956\n",
      "logistic_regression test score:0.979\n",
      "random forests (estimators: 100 max_depth: 5 max_feature: 2) 5-fold cross validation train/test: 0.993/0.960\n",
      "random_forest test score:0.979\n",
      "gradient_boost_regression (estimator: 100 learning_rate: 1.8) 5-fold cross validation train/test: 1.000/0.952\n",
      "gradient_boost_regression test score:0.979\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    data_file = input_file('./hw5_cancer.csv')\n",
    "    data_file.read_from_file()\n",
    "    raw_xdata, raw_ydata = data_file.sort_cancer_dataset()\n",
    "    \n",
    "    raw_xdata = np.array(raw_xdata)\n",
    "    raw_ydata = np.array(raw_ydata)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(raw_xdata, raw_ydata, test_size=94)\n",
    "\n",
    "    logistic_reg1 = logistic_reg(penalty_val='l2', max_iter_val=1000, C_val = 10)\n",
    "    train_avg, valid_avg = logistic_reg1.cross_valid(x_train, y_train)\n",
    "    score = logistic_reg1.score(x_test, y_test)\n",
    "    print(f'logistic_regression test score:{score:.3f}')\n",
    "\n",
    "    random_forest1 = random_forest(estimators_val=100, max_depth_val=5, max_feature_val=2)\n",
    "    train_avg, valid_avg = random_forest1.cross_valid(x_train, y_train)\n",
    "    score = random_forest1.score(x_test, y_test)\n",
    "    print(f'random_forest test score:{score:.3f}')\n",
    "\n",
    "    gradient_boost_reg1 = gradient_boost_reg(estimators_val=100, learning_rate_val=1.8)\n",
    "    train_avg, valid_avg = gradient_boost_reg1.cross_valid(x_train, y_train)\n",
    "    score = gradient_boost_reg1.score(x_test, y_test)\n",
    "    print(f'gradient_boost_regression test score:{score:.3f}')\n",
    "   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5fbbcf22b139417e008803b3e2cbc70cb85acf98954c351416a6d3da305ab5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
